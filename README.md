# ğŸ¬ IMDB NLP Sentiment Classification (Tarea NLP â€“ 3 Modelos)

Este repositorio implementa y compara **tres enfoques** para **clasificaciÃ³n de sentimiento** (positivo/negativo) sobre reseÃ±as IMDB, siguiendo un flujo NLP completo desde texto crudo hasta mÃ©tricas de evaluaciÃ³n:

- **Modelo A (clÃ¡sico):** TF-IDF + clasificador tradicional  
- **Modelo B (DL):** Embeddings estÃ¡ticos + RNN  
- **Modelo C (Transformer):** BERT (fine-tuning)

> Nota importante: este README estÃ¡ construido **a partir de la estructura del proyecto** (carpetas/archivos). Los hiperparÃ¡metros y rutas exactas se controlan en `configs/*.yaml`.

---

## âœ… Requisitos

- Conda (recomendado) o Python compatible con tu entorno.
- Dependencias definidas en:
  - `environment.yml` (entorno)
  - `pyproject.toml` (paquete / tooling)

---

## âš™ï¸ InstalaciÃ³n

### 1) Crear y activar el entorno (Conda)

```bash
conda env create -f environment.yml
conda activate imdb-nlp
```

### 2) Instalar el proyecto en modo editable

Desde la raÃ­z del repo:

```bash
pip install -e .
```

---

## ğŸ“ Estructura del proyecto

```
â”œâ”€â”€ configs
â”‚   â”œâ”€â”€ base.yaml
â”‚   â”œâ”€â”€ dataset.yaml
â”‚   â”œâ”€â”€ model_a_tfidf.yaml
â”‚   â”œâ”€â”€ model_b_static_emb.yaml
â”‚   â””â”€â”€ model_c_bert.yaml
â”œâ”€â”€ data
â”œâ”€â”€ environment.yml
â”œâ”€â”€ notebooks
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ src
â”‚   â””â”€â”€ nlp_imdb
â”‚       â”œâ”€â”€ cli
â”‚       â”‚   â””â”€â”€ main.py
â”‚       â”œâ”€â”€ data
â”‚       â”‚   â”œâ”€â”€ dataset_contract.md
â”‚       â”‚   â”œâ”€â”€ dataset_loader.py
â”‚       â”‚   â””â”€â”€ splits.py
â”‚       â”œâ”€â”€ features
â”‚       â”‚   â”œâ”€â”€ embeddings_static.py
â”‚       â”‚   â””â”€â”€ tfidf.py
â”‚       â”œâ”€â”€ models
â”‚       â”‚   â”œâ”€â”€ base.py
â”‚       â”‚   â”œâ”€â”€ model_a_tfidf.py
â”‚       â”‚   â”œâ”€â”€ model_b_rnn_static.py
â”‚       â”‚   â””â”€â”€ model_c_bert.py
â”‚       â”œâ”€â”€ preprocessing
â”‚       â”‚   â”œâ”€â”€ text_cleaning.py
â”‚       â”‚   â””â”€â”€ tokenization.py
â”‚       â”œâ”€â”€ training
â”‚       â”‚   â”œâ”€â”€ metrics.py
â”‚       â”‚   â”œâ”€â”€ result.py
â”‚       â”‚   â”œâ”€â”€ train_a.py
â”‚       â”‚   â”œâ”€â”€ train_b.py
â”‚       â”‚   â”œâ”€â”€ train_c.py
â”‚       â”‚   â””â”€â”€ trainer.py
â”‚       â””â”€â”€ utils
â”‚           â”œâ”€â”€ logging.py
â”‚           â”œâ”€â”€ paths.py
â”‚           â””â”€â”€ seed.py
â””â”€â”€ tests
    â”œâ”€â”€ conftest.py
    â””â”€â”€ test_smoke.py
```

---

## ğŸ§© Â¿QuÃ© hace cada mÃ³dulo?

### CLI (punto de entrada)
- `src/nlp_imdb/cli/main.py`  
  Ejecuta etapas (`--stage`) y carga configuraciÃ³n (`--config`). Es el comando que usarÃ¡s para entrenar cada modelo.

### Datos
- `src/nlp_imdb/data/dataset_contract.md`  
  Contrato/expectativas del dataset (formato esperado).
- `src/nlp_imdb/data/dataset_loader.py`  
  Carga el dataset y lo prepara para entrenamiento/evaluaciÃ³n.
- `src/nlp_imdb/data/splits.py`  
  LÃ³gica para particionar en train/val/test de forma reproducible.

### Preprocesamiento
- `src/nlp_imdb/preprocessing/text_cleaning.py`  
  Limpieza del texto (ruido bÃ¡sico: sÃ­mbolos, normalizaciÃ³n, etc.).
- `src/nlp_imdb/preprocessing/tokenization.py`  
  TokenizaciÃ³n y utilidades relacionadas (especialmente Ãºtil para el Modelo B y/o C).

### Features
- `src/nlp_imdb/features/tfidf.py`  
  ConstrucciÃ³n de features TF-IDF (Modelo A).
- `src/nlp_imdb/features/embeddings_static.py`  
  Embeddings estÃ¡ticos / matriz de embeddings (Modelo B).

### Modelos
- `src/nlp_imdb/models/base.py`  
  Interfaz/clase base comÃºn (si aplica).
- `src/nlp_imdb/models/model_a_tfidf.py`  
  DefiniciÃ³n del modelo A (pipeline clÃ¡sico).
- `src/nlp_imdb/models/model_b_rnn_static.py`  
  DefiniciÃ³n del modelo B (RNN + embeddings).
- `src/nlp_imdb/models/model_c_bert.py`  
  DefiniciÃ³n del modelo C (BERT / Transformer).

### Entrenamiento y evaluaciÃ³n
- `src/nlp_imdb/training/trainer.py`  
  Orquestador del entrenamiento (fit/evaluate, logging, guardado, etc.).
- `src/nlp_imdb/training/train_a.py` / `train_b.py` / `train_c.py`  
  Pipelines especÃ­ficos por modelo.
- `src/nlp_imdb/training/metrics.py`  
  MÃ©tricas (accuracy, precision, recall, f1, etc.).
- `src/nlp_imdb/training/result.py`  
  Estructuras de salida/resultados (formato final de reporting).

### Utilidades
- `src/nlp_imdb/utils/logging.py`  
  ConfiguraciÃ³n de logs.
- `src/nlp_imdb/utils/paths.py`  
  Manejo de rutas (data, outputs, etc.).
- `src/nlp_imdb/utils/seed.py`  
  Semillas para reproducibilidad.

### Tests
- `tests/test_smoke.py`  
  Prueba mÃ­nima para verificar que el pipeline â€œenciendeâ€ correctamente.
- `tests/conftest.py`  
  Fixtures de pytest.

---

## ğŸš€ CÃ³mo ejecutar cada modelo

El comando general es:

```bash
python -m nlp_imdb.cli.main --config <ruta_config.yaml> --stage <stage>
```

### â–¶ Modelo A (TF-IDF)

```bash
python -m nlp_imdb.cli.main --config configs/model_a_tfidf.yaml --stage train_a
```

### â–¶ Modelo B (Embeddings + RNN)

```bash
python -m nlp_imdb.cli.main --config configs/model_b_static_emb.yaml --stage train_b
```

### â–¶ Modelo C (BERT)

```bash
python -m nlp_imdb.cli.main --config configs/model_c_bert.yaml --stage train_c
```

---

## ğŸ§  Flujo NLP que demuestras en la tarea

### Modelo A (ClÃ¡sico)
1. Texto crudo â†’ limpieza (`text_cleaning.py`)
2. VectorizaciÃ³n TF-IDF (`tfidf.py`)
3. Entrenamiento clasificador (`model_a_tfidf.py` + `train_a.py`)
4. MÃ©tricas (`metrics.py`)

### Modelo B (Deep Learning)
1. Texto crudo â†’ limpieza
2. TokenizaciÃ³n + vocabulario (`tokenization.py`)
3. Embeddings estÃ¡ticos (`embeddings_static.py`)
4. RNN (p.ej. LSTM) (`model_b_rnn_static.py` + `train_b.py`)
5. MÃ©tricas

### Modelo C (Transformer)
1. Texto crudo â†’ tokenizaciÃ³n tipo BERT (en el pipeline del modelo)
2. Fine-tuning de BERT (`model_c_bert.py` + `train_c.py`)
3. MÃ©tricas

---

## ğŸ§ª Ejecutar pruebas

```bash
pytest -q
```

---

## ğŸ§¹ Sobre `__pycache__` y `.pyc`

Al ejecutar Python, se generan carpetas `__pycache__` y archivos `.pyc` (bytecode) automÃ¡ticamente para acelerar imports.  
No deben subirse al repo; tÃ­picamente se agregan al `.gitignore`:

```gitignore
__pycache__/
*.pyc
```

---

## ğŸ‘¤ Autor

Rodrigo CÃ¡ceres â€“ MagÃ­ster en Data Science

---

## ğŸ“„ Licencia

Uso acadÃ©mico (tarea).
